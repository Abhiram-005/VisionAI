# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DuHHGYlCw5txt0ICTCFy8ZIo82N167sR
"""

import warnings
warnings.filterwarnings("ignore", category=SyntaxWarning)
warnings.filterwarnings("ignore", category=UserWarning)

import streamlit as st
import torch
import segmentation_models_pytorch as smp
from torchvision import transforms as T
from PIL import Image
import numpy as np
import io
from huggingface_hub import hf_hub_download

# ----------------- STREAMLIT CONFIG -----------------
st.set_page_config(page_title="VisionExtract - AI Subject Isolation", layout="wide")

# ----------------- HEADER -----------------
st.markdown(
    """
    <div style="text-align: center; padding: 20px;">
        <h1 style="color:#2E86C1;">VisionExtract â€” AI-Powered Subject Isolation</h1>
        <p style="font-size:18px; color:#444; max-width:700px; margin:auto;">
            Automatically remove image backgrounds and isolate the main subject
            using state-of-the-art deep learning.
            Upload your own image or check out the demo below.
        </p>
    </div>
    """,
    unsafe_allow_html=True
)

# ----------------- DEMO SECTION -----------------
st.subheader("ðŸ”¹ Demo Preview")

demo_col1, demo_col2 = st.columns(2)

with demo_col1:
    st.image(
        "https://raw.githubusercontent.com/<your-username>/<repo-name>/main/demo_input.jpg",
        caption="Original Image", use_container_width=True
    )

with demo_col2:
    st.image(
        "https://raw.githubusercontent.com/<your-username>/<repo-name>/main/demo_output.png",
        caption="AI-Isolated Subject", use_container_width=True
    )

st.markdown("---")

# ----------------- MODEL LOADING -----------------
@st.cache_resource
def load_model_from_hf(repo_id, filename, device):
    """Download model from Hugging Face and load into memory (cached)."""
    model_path = hf_hub_download(repo_id=repo_id, filename=filename)

    model = smp.UnetPlusPlus(
        encoder_name="efficientnet-b5",
        encoder_weights=None,
        in_channels=3,
        classes=1
    )
    state = torch.load(model_path, map_location=device)
    model.load_state_dict(state)
    model.eval().to(device)
    return model

def image_to_tensor(pil_img, target_size=None):
    transforms = []
    if target_size:
        transforms.append(T.Resize(target_size))
    transforms.extend([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225])
    ])
    return T.Compose(transforms)(pil_img).unsqueeze(0)

def pad_image(pil_img):
    """Pad image so width and height are divisible by 32 (required by SMP)."""
    w, h = pil_img.size
    new_w = (w + 31) // 32 * 32
    new_h = (h + 31) // 32 * 32
    result = Image.new("RGB", (new_w, new_h))
    result.paste(pil_img, (0, 0))
    return result, (w, h)

def predict_mask(model, pil_img, device, threshold=0.5):
    """Run model inference and return binary mask."""
    padded_img, orig_size = pad_image(pil_img)
    x = image_to_tensor(padded_img).to(device)
    with torch.no_grad():
        out = model(x)
    out = out.cpu()
    if out.shape[1] == 1:
        mask = (torch.sigmoid(out)[0, 0].numpy() > threshold).astype('uint8') * 255
    else:
        mask = (out.argmax(1)[0].numpy() != 0).astype('uint8') * 255
    mask = Image.fromarray(mask).convert("L").resize(orig_size, Image.NEAREST)
    return mask

def apply_mask_to_image(pil_img, mask_pil):
    """Apply binary mask on original image."""
    img_np = np.array(pil_img.convert("RGB"))
    m = np.array(mask_pil) > 127
    out = np.zeros_like(img_np)
    out[m] = img_np[m]
    return Image.fromarray(out)

# ----------------- APP UI -----------------
DEVICE = torch.device("cpu")  # Streamlit Cloud = CPU only
HF_REPO = "Abhiram1705/VisionAI"   # ðŸ”¹ change this
MODEL_FILENAME = "unetpp_effb5.pth"

model = load_model_from_hf(HF_REPO, MODEL_FILENAME, DEVICE)

st.subheader("ðŸ”¹ Upload Your Image")

uploaded_file = st.file_uploader("Choose a file (PNG, JPG, JPEG)", type=["png", "jpg", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")

    # Resize large images for faster inference
    MAX_SIZE = 512
    if max(img.size) > MAX_SIZE:
        img.thumbnail((MAX_SIZE, MAX_SIZE))

    col1, col2 = st.columns(2)

    with col1:
        st.image(img, caption="Uploaded Image", use_container_width=True)
        # âœ… Button now below the uploaded image
        run_button = st.button("ðŸš€ Run AI Inference", use_container_width=True)

    with col2:
        if run_button:
            with st.spinner("Processing... Please wait..."):
                mask = predict_mask(model, img, DEVICE, threshold=0.5)
                result = apply_mask_to_image(img, mask)

                st.image(result, caption="Isolated Subject", use_container_width=True)

                buf = io.BytesIO()
                result.save(buf, format="PNG")
                buf.seek(0)
                st.download_button(
                    "â¬‡ Download Isolated Subject",
                    data=buf,
                    file_name="subject_isolated.png",
                    mime="image/png",
                    use_container_width=True
                )
else:
    st.info("ðŸ‘† Upload an image to get started!")