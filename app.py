# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DuHHGYlCw5txt0ICTCFy8ZIo82N167sR
"""

# -*- coding: utf-8 -*-
import warnings
warnings.filterwarnings("ignore", category=SyntaxWarning)
warnings.filterwarnings("ignore", category=UserWarning)

import streamlit as st
import torch
import segmentation_models_pytorch as smp
from torchvision import transforms as T
from PIL import Image
import numpy as np
import io
from huggingface_hub import hf_hub_download

# ----------------- STREAMLIT CONFIG -----------------
st.set_page_config(page_title="CutOut Pro - Smart Background Remover", layout="wide")

# ----------------- HERO SECTION -----------------
st.markdown(
    """
    <div style="text-align: center; padding: 30px;">
        <h1 style="color:#1E90FF; font-size: 42px; margin-bottom: 10px;">
            âœ¨ CutOut Pro â€” Smart Background Remover
        </h1>
        <p style="font-size:18px; color:#444; max-width:800px; margin:auto; line-height:1.6;">
            Transform your images effortlessly. <b>CutOut Pro</b> intelligently removes backgrounds,
            isolating your subject with professional accuracy.<br>
            Upload your own image or try the demo below!
        </p>
    </div>
    """,
    unsafe_allow_html=True
)

st.markdown("---")

# ----------------- DEMO SECTION -----------------
st.markdown("## ðŸ”¹ Demo Preview")
st.markdown(
    """
    <div style="text-align: center; margin-bottom: 20px; font-size:16px; color:#555;">
        See how our AI instantly isolates subjects with pixel-perfect precision.
    </div>
    """,
    unsafe_allow_html=True
)

st.markdown(
    """
    <div style="display: flex; justify-content: center; gap: 60px; margin-bottom: 50px;">
        <div style="text-align: center;">
            <img src="https://raw.githubusercontent.com/Abhiram-005/VisionAI/main/demo_input.png"
                 alt="Original Demo"
                 style="width:220px; border-radius:14px; box-shadow:0 4px 10px rgba(0,0,0,0.2);">
            <p style="margin-top:8px; font-size:14px; color:#444;">Original Image</p>
        </div>
        <div style="text-align: center;">
            <img src="https://raw.githubusercontent.com/Abhiram-005/VisionAI/main/demo_output.png"
                 alt="Isolated Subject"
                 style="width:220px; border-radius:14px; box-shadow:0 4px 10px rgba(0,0,0,0.2);">
            <p style="margin-top:8px; font-size:14px; color:#444;">AI-Isolated Subject</p>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)

st.markdown("---")

# ----------------- MODEL LOADING -----------------
@st.cache_resource
def load_model_from_hf(repo_id, filename, device):
    """Download model from Hugging Face and load into memory (cached)."""
    model_path = hf_hub_download(repo_id=repo_id, filename=filename)

    model = smp.UnetPlusPlus(
        encoder_name="efficientnet-b5",
        encoder_weights=None,
        in_channels=3,
        classes=1
    )
    state = torch.load(model_path, map_location=device)
    model.load_state_dict(state)
    model.eval().to(device)
    return model

def image_to_tensor(pil_img, target_size=None):
    transforms = []
    if target_size:
        transforms.append(T.Resize(target_size))
    transforms.extend([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225])
    ])
    return T.Compose(transforms)(pil_img).unsqueeze(0)

def pad_image(pil_img):
    """Pad image so width and height are divisible by 32 (required by SMP)."""
    w, h = pil_img.size
    new_w = (w + 31) // 32 * 32
    new_h = (h + 31) // 32 * 32
    result = Image.new("RGB", (new_w, new_h))
    result.paste(pil_img, (0, 0))
    return result, (w, h)

def predict_mask(model, pil_img, device, threshold=0.5):
    """Run model inference and return binary mask."""
    padded_img, orig_size = pad_image(pil_img)
    x = image_to_tensor(padded_img).to(device)
    with torch.no_grad():
        out = model(x)
    out = out.cpu()
    if out.shape[1] == 1:
        mask = (torch.sigmoid(out)[0, 0].numpy() > threshold).astype('uint8') * 255
    else:
        mask = (out.argmax(1)[0].numpy() != 0).astype('uint8') * 255
    mask = Image.fromarray(mask).convert("L").resize(orig_size, Image.NEAREST)
    return mask

def apply_mask_with_background(pil_img, mask_pil, bg_type="black", custom_color=None):
    """Apply mask with selected background (supports custom hex)."""
    img_rgba = pil_img.convert("RGBA")
    mask = np.array(mask_pil) > 127
    img_np = np.array(img_rgba)

    if bg_type == "transparent":
        out = np.zeros_like(img_np)
        out[..., :3] = img_np[..., :3]
        out[..., 3] = mask.astype(np.uint8) * 255
        return Image.fromarray(out)

    if bg_type == "custom" and custom_color:
        hex_color = tuple(int(custom_color.lstrip("#")[i:i+2], 16) for i in (0, 2, 4))
        bg_color = hex_color
    else:
        colors = {
            "black": (0, 0, 0),
            "white": (255, 255, 255),
            "blue": (0, 0, 255),
            "green": (0, 255, 0),
            "red": (255, 0, 0)
        }
        bg_color = colors.get(bg_type, (0, 0, 0))

    out = np.ones_like(img_np[..., :3]) * np.array(bg_color, dtype=np.uint8)
    out[mask] = img_np[mask, :3]
    return Image.fromarray(out)

# ----------------- APP UI -----------------
DEVICE = torch.device("cpu")
HF_REPO = "Abhiram1705/VisionAI"   # Replace with your HF repo
MODEL_FILENAME = "unetpp_effb5.pth"

model = load_model_from_hf(HF_REPO, MODEL_FILENAME, DEVICE)

# ----------------- UPLOAD SECTION -----------------
st.markdown("## ðŸ“¤ Try It Yourself")

uploaded_file = st.file_uploader("Upload an image (PNG, JPG, JPEG)", type=["png", "jpg", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")

    MAX_SIZE = 512
    if max(img.size) > MAX_SIZE:
        img.thumbnail((MAX_SIZE, MAX_SIZE))

    st.image(img, caption="Uploaded Image", use_container_width=True)

    run_button = st.button("ðŸš€ Run Background Removal", use_container_width=True)

    if run_button:
        with st.spinner("Processing... Please wait..."):
            mask = predict_mask(model, img, DEVICE, threshold=0.5)

        # Default output
        final_img = apply_mask_with_background(img, mask, bg_type="black")

        # Show final image first
        img_container = st.empty()
        img_container.image(final_img, caption="Background Removed", use_container_width=True)

        # Options BELOW the output
        bg_option = st.selectbox(
            "ðŸŽ¨ Choose Background:",
            ["black", "white", "blue", "green", "red", "transparent", "custom"]
        )

        custom_color = None
        if bg_option == "custom":
            custom_color = st.color_picker("Pick a custom background color", "#FF5733")

        # Update final image dynamically
        final_img = apply_mask_with_background(img, mask, bg_type=bg_option, custom_color=custom_color)
        img_container.image(final_img, caption=f"Output ({bg_option})", use_container_width=True)

        buf = io.BytesIO()
        final_img.save(buf, format="PNG")
        buf.seek(0)

        st.download_button(
            f"â¬‡ Download ({bg_option})",
            data=buf,
            file_name=f"cutout_{bg_option}.png",
            mime="image/png",
            use_container_width=True
        )
else:
    st.info("ðŸ‘† Upload an image to get started!")