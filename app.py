# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DuHHGYlCw5txt0ICTCFy8ZIo82N167sR
"""

import streamlit as st
import torch
import segmentation_models_pytorch as smp
from torchvision import transforms as T
from PIL import Image
import numpy as np
import io
from huggingface_hub import hf_hub_download

# ----------------- PAGE CONFIG -----------------
st.set_page_config(page_title="CutOut Pro ‚Äî Smart Background Remover", layout="wide")
st.title("‚ú® CutOut Pro ‚Äî Smart Background Remover")

st.markdown(
    """
    Transform your images effortlessly. **CutOut Pro** intelligently removes backgrounds,
    isolating your subject with professional accuracy.
    Upload your own image or try the demo below!
    """
)

# ----------------- MODEL LOADING -----------------
@st.cache_resource
def load_model_from_hf(repo_id, filename, device):
    try:
        model_path = hf_hub_download(repo_id=repo_id, filename=filename)
        model = smp.UnetPlusPlus(
            encoder_name="efficientnet-b5",
            encoder_weights=None,
            in_channels=3,
            classes=1
        )
        state = torch.load(model_path, map_location=device)
        model.load_state_dict(state)
        model.eval().to(device)
        return model
    except Exception as e:
        raise RuntimeError("Failed to load model: " + str(e))

def image_to_tensor(pil_img, target_size=None):
    transforms = []
    if target_size: transforms.append(T.Resize(target_size))
    transforms.extend([T.ToTensor(),
                       T.Normalize(mean=[0.485,0.456,0.406],
                                   std=[0.229,0.224,0.225])])
    return T.Compose(transforms)(pil_img).unsqueeze(0)

def pad_image(pil_img):
    w, h = pil_img.size
    new_w = (w + 31) // 32 * 32
    new_h = (h + 31) // 32 * 32
    result = Image.new("RGB", (new_w, new_h))
    result.paste(pil_img, (0, 0))
    return result, (w, h)

def predict_mask(model, pil_img, device, threshold=0.5):
    model.eval()
    padded_img, orig_size = pad_image(pil_img)
    x = image_to_tensor(padded_img).to(device)
    with torch.no_grad():
        out = model(x)
    out = out.cpu()
    if out.shape[1] == 1:
        mask = (torch.sigmoid(out)[0,0].numpy() > threshold).astype('uint8')*255
    else:
        mask = (out.argmax(1)[0].numpy() != 0).astype('uint8')*255
    mask = Image.fromarray(mask).convert("L").resize(orig_size, Image.NEAREST)
    return mask

def apply_mask_to_image(pil_img, mask_pil):
    img_np = np.array(pil_img.convert("RGB"))
    m = np.array(mask_pil) > 127
    out = np.zeros_like(img_np)
    out[m] = img_np[m]
    return Image.fromarray(out)

# ----------------- SETTINGS -----------------
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
HF_REPO = "your-hf-username/your-model-repo"   # üîπ Replace with your Hugging Face repo
MODEL_FILENAME = "unetpp_effb5.pth"            # üîπ Replace with your model filename

model = load_model_from_hf(HF_REPO, MODEL_FILENAME, DEVICE)

# ----------------- DEMO SECTION -----------------
st.markdown("## üîπ Demo Preview")

st.markdown(
    """
    <div style="display: flex; gap: 60px; justify-content: center; margin-top: 20px; margin-bottom: 30px;">
        <div>
            <img src="demo/demo_original.jpg" alt="Original Demo" width="220">
            <p style="text-align:center; font-size:14px;">Original Image (Demo)</p>
        </div>
        <div>
            <img src="demo/demo_isolated.jpg" alt="Isolated Demo" width="220">
            <p style="text-align:center; font-size:14px;">Isolated Subject (Demo)</p>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)

# ----------------- USER UPLOAD SECTION -----------------
st.markdown("## üì§ Try It Yourself")

col1, col2 = st.columns([1,1])

with col1:
    st.subheader("Upload Image")
    img_file = st.file_uploader("Choose an image", type=["png","jpg","jpeg"])
    run_inference = st.button("Remove the Background")

with col2:
    if img_file:
        img = Image.open(img_file).convert("RGB")
        st.image(img, caption="Original Image", width=350)
        if run_inference:
            with st.spinner("Processing..."):
                mask = predict_mask(model, img, DEVICE, threshold=0.5)
                result = apply_mask_to_image(img, mask)
                st.image(result, caption="Background Removed", width=350)
                buf = io.BytesIO()
                result.save(buf, format="PNG"); buf.seek(0)
                st.download_button("‚¨áÔ∏è Download Result (PNG)",
                                   data=buf, file_name="cutout_result.png", mime="image/png")
    else:
        st.info("Upload an image to get started.")