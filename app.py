# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DuHHGYlCw5txt0ICTCFy8ZIo82N167sR
"""

# -*- coding: utf-8 -*-
import warnings
warnings.filterwarnings("ignore", category=SyntaxWarning)
warnings.filterwarnings("ignore", category=UserWarning)

import streamlit as st
import torch
import segmentation_models_pytorch as smp
from torchvision import transforms as T
from PIL import Image
import numpy as np
import io
from huggingface_hub import hf_hub_download

# ----------------- STREAMLIT CONFIG -----------------
st.set_page_config(page_title="CutOut Pro - Smart Background Remover", layout="wide")

# ----------------- ANIMATED BACKGROUND -----------------
st.markdown(
    """
    <style>
    /* Full-page animated gradient background */
    body {
        background: linear-gradient(-45deg, #1E90FF, #00BFFF, #87CEFA, #4682B4);
        background-size: 400% 400%;
        animation: gradientBG 15s ease infinite;
    }

    @keyframes gradientBG {
        0% {background-position: 0% 50%;}
        50% {background-position: 100% 50%;}
        100% {background-position: 0% 50%;}
    }

    /* Streamlit container transparency */
    .stApp {
        background: transparent;
    }

    /* Center header */
    .main-header {
        text-align: center;
        padding: 20px;
    }

    h1 {
        color: #ffffff;
        font-size: 2.5em;
        font-weight: 700;
    }

    p {
        color: #f0f0f0;
        font-size: 18px;
    }

    /* Card style for demo + uploads */
    .stImage {
        border-radius: 15px;
        box-shadow: 0px 4px 15px rgba(0,0,0,0.25);
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ----------------- HEADER -----------------
st.markdown(
    """
    <div class="main-header">
        <h1>CutOut Pro â€” Smart Background Remover</h1>
        <p>
            Transform your images effortlessly. <b>CutOut Pro</b> intelligently removes backgrounds,
            isolating your subject with professional precision.<br>
            Upload your own image or explore the demo below.
        </p>
    </div>
    """,
    unsafe_allow_html=True
)

# ----------------- DEMO SECTION -----------------
st.subheader("ðŸ”¹ Demo Preview")

demo_col1, demo_col2 = st.columns(2)

with demo_col1:
    st.image(
        "https://raw.githubusercontent.com/Abhiram-005/VisionAI/main/demo_input.png",
        caption="Original Image", use_container_width=True
    )

with demo_col2:
    st.image(
        "https://raw.githubusercontent.com/Abhiram-005/VisionAI/main/demo_output.png",
        caption="AI-Isolated Subject", use_container_width=True
    )

st.markdown("---")

# ----------------- MODEL LOADING -----------------
@st.cache_resource
def load_model_from_hf(repo_id, filename, device):
    """Download model from Hugging Face and load into memory (cached)."""
    model_path = hf_hub_download(repo_id=repo_id, filename=filename)

    model = smp.UnetPlusPlus(
        encoder_name="efficientnet-b5",
        encoder_weights=None,
        in_channels=3,
        classes=1
    )
    state = torch.load(model_path, map_location=device)
    model.load_state_dict(state)
    model.eval().to(device)
    return model

def image_to_tensor(pil_img, target_size=None):
    transforms = []
    if target_size:
        transforms.append(T.Resize(target_size))
    transforms.extend([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225])
    ])
    return T.Compose(transforms)(pil_img).unsqueeze(0)

def pad_image(pil_img):
    """Pad image so width and height are divisible by 32 (required by SMP)."""
    w, h = pil_img.size
    new_w = (w + 31) // 32 * 32
    new_h = (h + 31) // 32 * 32
    result = Image.new("RGB", (new_w, new_h))
    result.paste(pil_img, (0, 0))
    return result, (w, h)

def predict_mask(model, pil_img, device, threshold=0.5):
    """Run model inference and return binary mask."""
    padded_img, orig_size = pad_image(pil_img)
    x = image_to_tensor(padded_img).to(device)
    with torch.no_grad():
        out = model(x)
    out = out.cpu()
    if out.shape[1] == 1:
        mask = (torch.sigmoid(out)[0, 0].numpy() > threshold).astype('uint8') * 255
    else:
        mask = (out.argmax(1)[0].numpy() != 0).astype('uint8') * 255
    mask = Image.fromarray(mask).convert("L").resize(orig_size, Image.NEAREST)
    return mask

def apply_mask_to_image(pil_img, mask_pil):
    """Apply binary mask on original image."""
    img_np = np.array(pil_img.convert("RGB"))
    m = np.array(mask_pil) > 127
    out = np.zeros_like(img_np)
    out[m] = img_np[m]
    return Image.fromarray(out)

# ----------------- APP UI -----------------
DEVICE = torch.device("cpu")  # Streamlit Cloud = CPU only
HF_REPO = "Abhiram1705/VisionAI"   # ðŸ”¹ change this
MODEL_FILENAME = "unetpp_effb5.pth"

model = load_model_from_hf(HF_REPO, MODEL_FILENAME, DEVICE)

st.subheader("ðŸ”¹ Upload Your Image")

uploaded_file = st.file_uploader("Choose a file (PNG, JPG, JPEG)", type=["png", "jpg", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")

    # Resize large images for faster inference
    MAX_SIZE = 512
    if max(img.size) > MAX_SIZE:
        img.thumbnail((MAX_SIZE, MAX_SIZE))

    col1, col2 = st.columns(2)

    with col1:
        st.image(img, caption="Uploaded Image", use_container_width=True)
        # âœ… Button now directly below the uploaded image
        run_button = st.button("ðŸš€ Run Background Removal", use_container_width=True)

    with col2:
        if run_button:
            with st.spinner("Processing... Please wait..."):
                mask = predict_mask(model, img, DEVICE, threshold=0.5)
                result = apply_mask_to_image(img, mask)

                st.image(result, caption="Isolated Subject", use_container_width=True)

                buf = io.BytesIO()
                result.save(buf, format="PNG")
                buf.seek(0)
                st.download_button(
                    "â¬‡ Download Processed Image",
                    data=buf,
                    file_name="cutout_result.png",
                    mime="image/png",
                    use_container_width=True
                )
else:
    st.info("ðŸ‘† Upload an image to get started!")